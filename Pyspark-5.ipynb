{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c33cbe2",
   "metadata": {},
   "source": [
    "## GroupBy And Aggregate Functions In Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27377ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977f518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Dataframe_Use').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe36585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-NAQQF69A:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe_Use</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x193532c3eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac71554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a0c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Azam\\Desktop\\Extra Work\\Udemy ML\\UNZIP_FOR_NOTEBOOKS_FINAL\\03-Pandas\\movie_scores.csv\"\n",
    "path =r\"C:\\Users\\Azam\\Desktop\\Extra Work\\Udemy ML\\UNZIP_FOR_NOTEBOOKS_FINAL\\03-Pandas\\Sales_Funnel_CRM.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e9e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the dataset\n",
    "df_pyspark=spark.read.option('header','true').csv(path,inferSchema=True) # IF inferSchema is not set to true then Pyspark will treat all the columns as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d7a936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------+---------------+---------------+--------+----------+------------+\n",
      "|Account Number|     Company|     Contact|Account Manager|        Product|Licenses|Sale Price|      Status|\n",
      "+--------------+------------+------------+---------------+---------------+--------+----------+------------+\n",
      "|       2123398|      Google| Larry Pager|   Edward Thorp|      Analytics|     150|   2100000|   Presented|\n",
      "|       2123398|      Google| Larry Pager|   Edward Thorp|     Prediction|     150|    700000|   Presented|\n",
      "|       2123398|      Google| Larry Pager|   Edward Thorp|       Tracking|     300|    350000|Under Review|\n",
      "|       2192650|        BOBO| Larry Pager|   Edward Thorp|      Analytics|     150|   2450000|        Lost|\n",
      "|        420496|        IKEA|   Elon Tusk|   Edward Thorp|      Analytics|     300|   4550000|         Won|\n",
      "|        636685|  Tesla Inc.|   Elon Tusk|   Edward Thorp|      Analytics|     300|   2800000|Under Review|\n",
      "|        636685|  Tesla Inc.|   Elon Tusk|   Edward Thorp|     Prediction|     150|    700000|   Presented|\n",
      "|       1216870|   Microsoft| Will Grates|   Edward Thorp|       Tracking|     300|    350000|Under Review|\n",
      "|       2200450|     Walmart| Will Grates|   Edward Thorp|      Analytics|     150|   2450000|        Lost|\n",
      "|        405886|       Apple|Cindy Phoner| Claude Shannon|      Analytics|     300|   4550000|         Won|\n",
      "|        470248|Exxon Mobile|Cindy Phoner| Claude Shannon|      Analytics|     150|   2100000|   Presented|\n",
      "|        698032|         ATT|Cindy Phoner| Claude Shannon|       Tracking|     150|    350000|Under Review|\n",
      "|        698032|         ATT|Cindy Phoner| Claude Shannon|     Prediction|     150|    700000|   Presented|\n",
      "|        902797|  CVS Health|Emma Gordian| Claude Shannon|       Tracking|     450|    490000|         Won|\n",
      "|       2046943|  Salesforce|Emma Gordian| Claude Shannon|      Analytics|     750|   7000000|         Won|\n",
      "|       2169499|       Cisco|Emma Gordian| Claude Shannon|      Analytics|     300|   4550000|        Lost|\n",
      "|       2169499|       Cisco|Emma Gordian| Claude Shannon|GPS Positioning|     300|    350000|   Presented|\n",
      "+--------------+------------+------------+---------------+---------------+--------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ebc7658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-------------+---------------+\n",
      "|     Company|sum(Account Number)|sum(Licenses)|sum(Sale Price)|\n",
      "+------------+-------------------+-------------+---------------+\n",
      "|     Walmart|            2200450|          150|        2450000|\n",
      "|  CVS Health|             902797|          450|         490000|\n",
      "|  Salesforce|            2046943|          750|        7000000|\n",
      "|       Cisco|            4338998|          600|        4900000|\n",
      "|Exxon Mobile|             470248|          150|        2100000|\n",
      "|   Microsoft|            1216870|          300|         350000|\n",
      "|  Tesla Inc.|            1273370|          450|        3500000|\n",
      "|         ATT|            1396064|          300|        1050000|\n",
      "|      Google|            6370194|          600|        3150000|\n",
      "|       Apple|             405886|          300|        4550000|\n",
      "|        BOBO|            2192650|          150|        2450000|\n",
      "|        IKEA|             420496|          300|        4550000|\n",
      "+------------+-------------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Company').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aacc4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|     Company|count|\n",
      "+------------+-----+\n",
      "|     Walmart|    1|\n",
      "|  CVS Health|    1|\n",
      "|  Salesforce|    1|\n",
      "|       Cisco|    2|\n",
      "|Exxon Mobile|    1|\n",
      "|   Microsoft|    1|\n",
      "|  Tesla Inc.|    2|\n",
      "|         ATT|    2|\n",
      "|      Google|    3|\n",
      "|       Apple|    1|\n",
      "|        BOBO|    1|\n",
      "|        IKEA|    1|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Company').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b83e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+---------------+\n",
      "|     Company|Number of Statuses|Mean Sale Price|\n",
      "+------------+------------------+---------------+\n",
      "|     Walmart|                 1|      2450000.0|\n",
      "|  CVS Health|                 1|       490000.0|\n",
      "|  Salesforce|                 1|      7000000.0|\n",
      "|       Cisco|                 2|      2450000.0|\n",
      "|Exxon Mobile|                 1|      2100000.0|\n",
      "|   Microsoft|                 1|       350000.0|\n",
      "|  Tesla Inc.|                 2|      1750000.0|\n",
      "|         ATT|                 2|       525000.0|\n",
      "|      Google|                 3|      1050000.0|\n",
      "|       Apple|                 1|      4550000.0|\n",
      "|        BOBO|                 1|      2450000.0|\n",
      "|        IKEA|                 1|      4550000.0|\n",
      "+------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In PySpark, the groupBy() function is used to group rows of a DataFrame based on one or more columns, and the agg() method is\n",
    "used to perform aggregate operations on the grouped data. The agg() method allows you to specify one or more aggregate functions\n",
    "to apply to each group.\n",
    "'''\n",
    "\n",
    "df_pyspark.groupBy('Company').agg(count('Status').alias('Number of Statuses'),avg('Sale Price').alias('Mean Sale Price')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599648e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b5ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
